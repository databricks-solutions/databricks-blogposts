{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db75c066-288e-4d52-b9a0-89200cf1a083",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLflow: \n",
    "### `Log data, dependencies, model, metrics etc. to Unity Catalog`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81923d4b-cb4d-4052-9945-1b4d691f1c36",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "clear existing table"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %sql\n",
    "# DROP TABLE IF EXISTS mmt_demos.dependencies.iris_data;\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS mmt_demos.dependencies.iris_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f17a8348-f127-465b-8eb5-1d90595b0435",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "clear model & version(s)"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Set registry to Unity Catalog \n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Initialize the MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"mmt_demos.dependencies.iris_rfclassifier\"\n",
    "\n",
    "# List all versions of the model\n",
    "versions = [mv.version for mv in client.search_model_versions(f\"name='{model_name}'\")]\n",
    "\n",
    "# Delete all versions of the model\n",
    "for version in versions:\n",
    "    client.delete_model_version(name=model_name, version=version)\n",
    "\n",
    "# Delete the registered model\n",
    "client.delete_registered_model(name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bada4379-8a77-4016-981a-faa01c01b940",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "clear specific model version"
    }
   },
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "# # Set registry to Unity Catalog \n",
    "# mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# # Delete version 3 of the model\n",
    "# model_name = \"mmt_demos.dependencies.iris_rfclassifier\"\n",
    "# version = 3\n",
    "\n",
    "# mlflow.registered_model.delete_model_version(name=model_name, version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bce5402-d9d6-433e-99f5-35fea8420bcc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check version"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.9.2'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__ \n",
    "#'2.9.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f5ab66f-d6a6-49c8-a341-0f1390e50d80",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "import modules"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "from sklearn.datasets import load_iris\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import accuracy_score \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f936db0-f555-41aa-a85e-6590c69f7b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the volume in Unity Catalog\n",
    "spark.sql(\"CREATE VOLUME IF NOT EXISTS mmt_demos.dependencies.iris_rfclassifier\")\n",
    "\n",
    "# Create the directory within the volume\n",
    "volume_path = \"/Volumes/mmt_demos/dependencies/iris_rfclassifier\"\n",
    "dbutils.fs.mkdirs(volume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cadfcfc4-9ad8-4aaa-aaff-a3f2109056fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/dbfs/Volumes/mmt_demos/dependencies/iris_rfclassifier/', name='iris_rfclassifier/', size=0, modificationTime=1745284722422)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/dbfs/Volumes/mmt_demos/dependencies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be9c3c40-c011-439d-9141-b65a0adfab09",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "paths & data"
    }
   },
   "outputs": [],
   "source": [
    "# Get the user's home directory path\n",
    "user_path = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "\n",
    "# Write a table to Unity Catalog\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df.rename(\n",
    "  columns={col: col.replace(' (cm)', '').replace(' ', '_') for col in iris_df.columns},\n",
    "  inplace=True\n",
    ")\n",
    "iris_df['species'] = iris.target\n",
    "ps.from_pandas(iris_df).to_table(\"mmt_demos.dependencies.iris_data\", mode=\"overwrite\")\n",
    "# table version could be specified during model logging\n",
    "\n",
    "# Define the conda environment\n",
    "conda_env = \"\"\"\n",
    "name: mlflow-env\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.8.5\n",
    "  - scikit-learn=0.24.1\n",
    "  - mlflow=2.9.2\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    - pandas\n",
    "    - pyspark\n",
    "\"\"\"\n",
    "\n",
    "# Write the conda_env to a UC Volume for subsequent reference in model logging\n",
    "# Create the volume in Unity Catalog\n",
    "# spark.sql(\"CREATE VOLUME IF NOT EXISTS mmt_demos.dependencies.iris_rfclassifier\")\n",
    "\n",
    "# Create the volume path\n",
    "volume_path = \"/Volumes/mmt_demos/dependencies/iris_rfclassifier\"\n",
    "dbutils.fs.mkdirs(volume_path)\n",
    "\n",
    "# Write the conda_env to the volume\n",
    "conda_env_volume_path = f\"{volume_path}/conda_env.yaml\"\n",
    "os.makedirs(os.path.dirname(conda_env_volume_path), exist_ok=True)\n",
    "with open(f\"{conda_env_volume_path}\", \"w\") as f:\n",
    "    f.write(conda_env)\n",
    "\n",
    "# Load a Unity Catalog table, train a model, and log the input table\n",
    "dataset = mlflow.data.load_delta(table_name=\"mmt_demos.dependencies.iris_data\", version=\"0\") ## table version could be specified during model logging\n",
    "pd_df = dataset.df.toPandas()\n",
    "X = pd_df.drop(\"species\", axis=1)\n",
    "y = pd_df[\"species\"]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert integer columns to float64 to handle missing values\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ab702f3-e8c0-45f8-9892-314336a32ded",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "iris_data_rfclassifier"
    }
   },
   "outputs": [],
   "source": [
    "# Set registry to Unity Catalog \n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Set the experiment explicitly\n",
    "experiment_path = f\"/Users/{user_path}/mlflow_experiments/dependencies/iris_data_rfclassifier\"\n",
    "os.makedirs(os.path.dirname(experiment_path), exist_ok=True)\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "# Define the parameters for the Random Forest model\n",
    "# params = {\"n_estimators\": 3, \"random_state\": 432}\n",
    "params = {\n",
    "    \"n_estimators\": 5,\n",
    "    \"random_state\": 432,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_samples_split\": 20,\n",
    "    \"min_samples_leaf\": 10,\n",
    "    \"max_features\": \"log2\", #\"sqrt\",\n",
    "    \"bootstrap\": True\n",
    "}\n",
    "\n",
    "# Train a model, log input table, parameters, metrics etc.\n",
    "with mlflow.start_run() as run:\n",
    "    # Define the model\n",
    "    rfc = RandomForestClassifier(**params).fit(X_train, y_train)\n",
    "\n",
    "    # Specify the required model input and output schema \n",
    "    signature = infer_signature(X_train, rfc.predict(X_train))\n",
    "    mlflow.log_input(dataset, \"training\")\n",
    "    # Take the first row of the training dataset as the model input example.\n",
    "    input_example = X_train.iloc[[0]]\n",
    "    # Log the model and register it as a new version in UC.\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    ## Track model metrics with experiment run for subsequent comparisons \n",
    "    # Calculate and log training metrics\n",
    "    train_predictions = rfc.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
    "    train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
    "    # Log the test metrics\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    mlflow.log_metric(\"train_precision\", train_precision)\n",
    "    mlflow.log_metric(\"train_recall\", train_recall)\n",
    "    \n",
    "    # Calculate and log test metrics\n",
    "    test_predictions = rfc.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "    test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    test_recall = recall_score(y_test, test_predictions, average='weighted')\\\n",
    "    # Log the test metrics\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"test_precision\", test_precision)\n",
    "    mlflow.log_metric(\"test_recall\", test_recall)\n",
    "    \n",
    "    # Log the model and register it as a new version in UC \n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rfc,        \n",
    "        artifact_path=\"sklearn-rfclassifier-model\",  \n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        conda_env=conda_env_volume_path,\n",
    "        registered_model_name=\"mmt_demos.dependencies.iris_rfclassifier\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3297f625-a75a-4c76-8faa-ba057932a4c3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test register via model_uri"
    }
   },
   "outputs": [],
   "source": [
    "# [Alternatively] Register outside of model logging\n",
    "model_uri = f\"runs:/{run.info.run_id}/sklearn-rfclassifier-model\"\n",
    "print(model_uri)\n",
    "\n",
    "catalog_name = \"mmt_demos\"\n",
    "schema_name = \"dependencies\"\n",
    "\n",
    "mv = mlflow.register_model(model_uri,                \n",
    "                           f\"{catalog_name}.{schema_name}.iris_rfclassifier\"\n",
    "                           )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "codesnippets_log_dataNmodel",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
